# configs/defaults/a2c_params.yaml
# A2C (Advantage Actor-Critic) specific hyperparameters
a2c_params:
  total_timesteps: 500000             # Total number of samples to train on
  learning_rate: 0.0007               # Learning rate for the Adam optimizer
  n_steps: 5                          # The number of steps to run for each environment per update
  gamma: 0.99                         # Discount factor
  gae_lambda: 1.0                     # Factor for trade-off of bias vs variance for GAE
  ent_coef: 0.01                      # Entropy coefficient for the loss calculation
  vf_coef: 0.25                       # Value function coefficient for the loss calculation
  max_grad_norm: 0.5                  # The maximum value for the gradient clipping
  use_sde: False                      # Whether to use generalized State Dependent Exploration (SDE)
  policy_kwargs: "{'net_arch': [64, 64]}" # Network architecture for the policy and value function (as string)